#!/usr/bin/python

# Contains functions for compressing/recovering (english) text. Input to both functions
# is a generative model which predicts a probability distribution over the possible characters.

# A list of allowed characters. The model must return a map of probabilities whose domain
# consists of this list. Note that this list contains all letters, numbers, and special symbols
# so this shouldn't be at all restrictive.

character_list = [chr(i) for i in range(32,127)]

# The resolution of the encoding process, i.e. probabilities generated by the model are 
# incorporated at least to an accuracy of 1/(resolution).

resolution = 1073741824;

def compress(text, model):
	message_length = len(text)
	compressed_message = []
	bottom = 0
	top = 2*resolution
	max_val = top
	for a in text:
		probs = model.probabilities()
		current_res = top - bottom
		while current_res < resolution:
			top *= 2
			bottom *= 2
			max_val *= 2
			current_res *= 2
		for x in [i for i in character_list if ord(i) < ord(a)]:
			bottom += int(probs[x]*current_res)
		top = bottom + int(probs[a]*current_res)
		while bottom >= max_val // 2 or top < max_val // 2:
			if bottom >= max_val // 2:
				compressed_message.append(True) # represents a 1.
				bottom -= (max_val // 2)
				top -= (max_val // 2)
				max_val = max_val // 2
			elif top < max_val // 2:
				compressed_message.append(False) # represents a 0.
				max_val = max_val // 2
		model.next_char(a) # Tells the model what the current character is so it can update the probability distribution of the next character.
	return [message_length, compressed_message]
		
